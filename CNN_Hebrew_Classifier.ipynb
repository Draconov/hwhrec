{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Draconov/hwhrec/blob/main/CNN_Hebrew_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed0fd4e0",
      "metadata": {
        "id": "ed0fd4e0"
      },
      "source": [
        "# ðŸ§  CNN Classifier for Handwritten Hebrew Letters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "83e355f4",
      "metadata": {
        "id": "83e355f4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "67e2438c",
      "metadata": {
        "id": "67e2438c"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        return None\n",
        "    h, w = img.shape\n",
        "    if h > w:\n",
        "        pad = (h - w) // 2\n",
        "        img = cv2.copyMakeBorder(img, 0, 0, pad, h - w - pad, cv2.BORDER_CONSTANT, value=255)\n",
        "    elif w > h:\n",
        "        pad = (w - h) // 2\n",
        "        img = cv2.copyMakeBorder(img, pad, w - h - pad, 0, 0, cv2.BORDER_CONSTANT, value=255)\n",
        "    img = cv2.resize(img, (32, 32))\n",
        "    img = 255 - img\n",
        "    return img.astype(np.float32) / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "eda705e9",
      "metadata": {
        "id": "eda705e9"
      },
      "outputs": [],
      "source": [
        "def load_dataset(base_dir):\n",
        "    X, y = [], []\n",
        "    for label in range(27):\n",
        "        folder = os.path.join(base_dir, str(label))\n",
        "        if not os.path.exists(folder): continue\n",
        "        for fname in os.listdir(folder):\n",
        "            img_path = os.path.join(folder, fname)\n",
        "            img = preprocess_image(img_path)\n",
        "            if img is not None:\n",
        "                X.append(img.reshape(32, 32, 1))\n",
        "                y.append(label)\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cc918cfa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "cc918cfa",
        "outputId": "7dad9703-3853-4445-c56c-08cbae467965"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-48000b3fab81>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed_hhd/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed_hhd/test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ],
      "source": [
        "X, y = load_dataset('processed_hhd/train')\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n",
        "X_test, y_test = load_dataset('processed_hhd/test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e8f35d2",
      "metadata": {
        "id": "4e8f35d2"
      },
      "outputs": [],
      "source": [
        "def build_cnn():\n",
        "    model = Sequential()\n",
        "    for filters in [32, 64, 128]:\n",
        "        model.add(Conv2D(filters, (3, 3), activation='relu', padding='same'))\n",
        "        model.add(Conv2D(filters, (3, 3), activation='relu', padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(27, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c251aa93",
      "metadata": {
        "id": "c251aa93"
      },
      "outputs": [],
      "source": [
        "model = build_cnn()\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50de2f50",
      "metadata": {
        "id": "50de2f50"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    rotation_range=10,\n",
        "    shear_range=0.2,\n",
        "    brightness_range=(0.2, 1.8))\n",
        "datagen.fit(X_train)\n",
        "model_aug = build_cnn()\n",
        "history_aug = model_aug.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
        "                             validation_data=(X_val, y_val), epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2acccb6",
      "metadata": {
        "id": "e2acccb6"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], label='Train Loss (no aug)')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss (no aug)')\n",
        "plt.plot(history_aug.history['loss'], label='Train Loss (aug)')\n",
        "plt.plot(history_aug.history['val_loss'], label='Val Loss (aug)')\n",
        "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Training and Validation Loss')\n",
        "plt.legend(); plt.grid(True); plt.savefig('loss_curve.png'); plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20cf9082",
      "metadata": {
        "id": "20cf9082"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(model_aug.predict(X_test), axis=1)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "acc_per_class = cm.diagonal() / cm.sum(axis=1)\n",
        "for i, acc in enumerate(acc_per_class):\n",
        "    print(f'Letter {i}: {acc:.2f}')\n",
        "print('Average accuracy:', acc_per_class.mean())\n",
        "pd.DataFrame(cm).to_csv('confusion_matrix.csv', index=False)\n",
        "with open('results.txt', 'w') as f:\n",
        "    f.write('Letter    Accuracy\\n')\n",
        "    for i, acc in enumerate(acc_per_class):\n",
        "        f.write(f'{i:<10}{acc:.4f}\\n')\n",
        "    f.write(f'\\nAverage accuracy: {acc_per_class.mean():.4f}\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}